{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XzIujvvXK7Wo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "seed = 1234\n",
    "import pandas as pd\n",
    "import os, glob\n",
    "import numpy as np\n",
    "np.random.seed(seed)\n",
    "import random\n",
    "random.seed(seed)\n",
    "# fix random seed for reproducibility\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.random.set_random_seed(seed)\n",
    "import keras\n",
    "from numpy import array\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import text_utilities as tu\n",
    "import modeling_utils as mu\n",
    "import image_utilities as iu\n",
    "import ocr\n",
    "import doc_classifier_model as dcm\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from keras import backend as K\n",
    "import json\n",
    "\n",
    "sess_config = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1,\n",
    "allow_soft_placement=True, device_count = {'CPU': 1})\n",
    "sess = tf.Session(graph=tf.get_default_graph(),config=sess_config)\n",
    "K.set_session(sess)\n",
    "\n",
    "plt.style.use('ggplot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n",
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2DPmmV0NMlg_"
   },
   "source": [
    "## **OCR function applied on images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y_aY4TMNMESt"
   },
   "outputs": [],
   "source": [
    "#data_path = '/home/sureclaim/Documents/Claims/real_data/'\n",
    "#data_df = ocr.create_data_df(data_path)\n",
    "#data_df.to_csv('/home/sureclaim/Documents/Claims/data_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1946, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv('data/data_df_new.csv')\n",
    "#data_df = pd.read_csv('/home/sureclaim/Documents/Claims/data_df.csv')\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NA counts: Unnamed: 0     0\n",
      "filename       0\n",
      "path           0\n",
      "x_txt         65\n",
      "y              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"NA counts:\", data_df.isna().sum())\n",
    "data_df = data_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DV distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>y</th>\n",
       "      <th>Aadhar Card</th>\n",
       "      <th>Diagnostic Bill</th>\n",
       "      <th>Discharge Summary</th>\n",
       "      <th>Insurance Card</th>\n",
       "      <th>Internal Case Papers</th>\n",
       "      <th>Pan Card</th>\n",
       "      <th>Phramacy Bill</th>\n",
       "      <th>Policy Copy</th>\n",
       "      <th>Prescriptions</th>\n",
       "      <th>Receipts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>counts</th>\n",
       "      <td>112.00</td>\n",
       "      <td>114.00</td>\n",
       "      <td>268.00</td>\n",
       "      <td>111.0</td>\n",
       "      <td>277.00</td>\n",
       "      <td>46.00</td>\n",
       "      <td>306.00</td>\n",
       "      <td>145.00</td>\n",
       "      <td>312.00</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perc (%)</th>\n",
       "      <td>5.95</td>\n",
       "      <td>6.06</td>\n",
       "      <td>14.25</td>\n",
       "      <td>5.9</td>\n",
       "      <td>14.73</td>\n",
       "      <td>2.45</td>\n",
       "      <td>16.27</td>\n",
       "      <td>7.71</td>\n",
       "      <td>16.59</td>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "y         Aadhar Card  Diagnostic Bill  Discharge Summary  Insurance Card  \\\n",
       "counts         112.00           114.00             268.00           111.0   \n",
       "perc (%)         5.95             6.06              14.25             5.9   \n",
       "\n",
       "y         Internal Case Papers  Pan Card  Phramacy Bill  Policy Copy  \\\n",
       "counts                  277.00     46.00         306.00       145.00   \n",
       "perc (%)                 14.73      2.45          16.27         7.71   \n",
       "\n",
       "y         Prescriptions  Receipts  \n",
       "counts           312.00     190.0  \n",
       "perc (%)          16.59      10.1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encode category\n",
    "data_df['y_oneh'] = mu.onehot_encode(data_df.y)\n",
    "mu.get_dv_dist(data_df, 'filename', 'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "K2cQJiunPX9-",
    "outputId": "8363698b-0443-47aa-bfb6-a79fbb01b83d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 29366\n"
     ]
    }
   ],
   "source": [
    "# Clean the text column; keep only alphabets\n",
    "data_df['x_txt_cleaned'] = data_df.x_txt.apply(tu.clean_string)\n",
    "\n",
    "# Setting max padded sequence length = 70\n",
    "max_len = 70\n",
    "vocab = tu.make_vocab(data_df.x_txt_cleaned)\n",
    "w2i = tu.make_w2i(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Train X Size: (1316, 2)\n",
      "Train Y Size: (1316,)\n",
      "----------------------------------------\n",
      "Test X size: (565, 2)\n",
      "Test Y Size: (565,)\n"
     ]
    }
   ],
   "source": [
    "# Shuffle dataframe\n",
    "data_df = data_df.sample(frac=1)\n",
    "\n",
    "# Get word level splits\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_df[['path', 'x_txt_cleaned']], data_df.y_oneh, test_size=0.3, random_state=201)\n",
    "\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Train X Size:\", x_train.shape)\n",
    "print(\"Train Y Size:\", y_train.shape)\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Test X size:\", x_test.shape)\n",
    "print(\"Test Y Size:\", y_test.shape)\n",
    "\n",
    "# TODO show DV dist for every sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Hw81mNQh4VD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X text train tensor shape: (1316, 70)\n",
      "X images train tensor shape: (1316, 131072)\n",
      "y train shape: (1316, 10)\n",
      "----------------------------------------\n",
      "X text test tensor shape: (565, 70)\n",
      "X images test tensor shape: (565, 131072)\n",
      "y test shape: (565, 10)\n"
     ]
    }
   ],
   "source": [
    "# make tensors\n",
    "x_txt_train = tu.make_tensor_np(x_train.x_txt_cleaned, w2i, max_len)\n",
    "#x_img_train = np.stack(x_train.path.apply(rfe.generate_image_features, args=[resnet50]))\n",
    "#np.save('data/img_features_train_new.npy', x_img_train)\n",
    "x_img_train = np.load('data/img_features_train.npy')\n",
    "y_train = np.stack(y_train.to_numpy())\n",
    "\n",
    "x_txt_test = tu.make_tensor_np(x_test.x_txt_cleaned, w2i, max_len)\n",
    "#x_img_test = np.stack(x_test.path.apply(rfe.generate_image_features, args=[resnet50]))\n",
    "#np.save('data/img_features_test_new.npy', x_img_test)\n",
    "x_img_test = np.load('data/img_features_test.npy')\n",
    "y_test = np.stack(y_test.to_numpy())\n",
    "\n",
    "print(\"X text train tensor shape:\", x_txt_train.shape)\n",
    "print(\"X images train tensor shape:\", x_img_train.shape)\n",
    "print(\"y train shape:\", y_train.shape)\n",
    "print(\"----------------------------------------\")\n",
    "print(\"X text test tensor shape:\", x_txt_test.shape)\n",
    "print(\"X images test tensor shape:\", x_img_test.shape)\n",
    "print(\"y test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DV Distribution by Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DV distribution:----------------------------------------------------------------------- \n",
      "            0     1      2     3      4     5      6      7      8      9\n",
      "counts   85.0  77.0  191.0  78.0  199.0  33.0  213.0  107.0  205.0  128.0\n",
      "perc(%)   6.5   5.9   14.5   5.9   15.1   2.5   16.2    8.1   15.6    9.7\n",
      "Test DV distribution:------------------------------------------------------------------------ \n",
      "            0     1     2     3     4     5     6     7      8     9\n",
      "counts   27.0  37.0  77.0  33.0  78.0  13.0  93.0  38.0  107.0  62.0\n",
      "perc(%)   4.8   6.5  13.6   5.8  13.8   2.3  16.5   6.7   18.9  11.0\n"
     ]
    }
   ],
   "source": [
    "# TODO: make reports, write to csv\n",
    "print(\"Train DV distribution:----------------------------------------------------------------------- \")\n",
    "print(mu.get_dv_dist(y_train))\n",
    "print(\"Test DV distribution:------------------------------------------------------------------------ \")\n",
    "print(mu.get_dv_dist(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_classes = y_test.shape[1]\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "config = dict({'input_text_shape': max_len, 'input_img_shape': x_img_train.shape[1], 'n_classes': n_classes, 'vocab_size': vocab_size, 'w2i':w2i})\n",
    "\n",
    "with open('model_config', 'w') as configfile:\n",
    "    json.dump(config, configfile, indent=2)\n",
    "\n",
    "doc_classifier = dcm.build_doc_classifier(max_len, x_img_train.shape[1], n_classes, vocab_size)\n",
    "\n",
    "## Defining keras callbacks\n",
    "log_dir = 'models/tf-log/'\n",
    "tb_cb = TensorBoard(log_dir=log_dir, histogram_freq=0)\n",
    "\n",
    "model_checkpoint = ModelCheckpoint('models/doc_classifier.ckpt', monitor='f1', save_weights_only=True, mode = 'max', save_best_only=True, verbose=2)\n",
    "early_stopping = EarlyStopping(monitor='f1', mode = 'max', patience=30, verbose=2)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='f1', mode = 'max', factor=0.5, patience=5, min_lr=0.00001, verbose=2)\n",
    "cbks = [tb_cb, early_stopping, reduce_lr, model_checkpoint]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1184 samples, validate on 132 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/30\n",
      "1184/1184 [==============================] - 44s 38ms/step - loss: 8.0693 - accuracy: 0.1757 - f1: 0.1672 - val_loss: 4.9495 - val_accuracy: 0.3864 - val_f1: 0.1761\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "\n",
      "Epoch 00001: f1 improved from -inf to 0.16718, saving model to models/doc_classifier.ckpt\n",
      "Epoch 2/30\n",
      "1184/1184 [==============================] - 42s 36ms/step - loss: 5.2887 - accuracy: 0.3167 - f1: 0.2876 - val_loss: 4.1833 - val_accuracy: 0.4091 - val_f1: 0.3723\n",
      "\n",
      "Epoch 00002: f1 improved from 0.16718 to 0.28756, saving model to models/doc_classifier.ckpt\n",
      "Epoch 3/30\n",
      "1184/1184 [==============================] - 44s 37ms/step - loss: 4.5067 - accuracy: 0.4079 - f1: 0.3841 - val_loss: 3.6497 - val_accuracy: 0.4318 - val_f1: 0.3646\n",
      "\n",
      "Epoch 00003: f1 improved from 0.28756 to 0.38411, saving model to models/doc_classifier.ckpt\n",
      "Epoch 4/30\n",
      "1184/1184 [==============================] - 44s 37ms/step - loss: 3.8999 - accuracy: 0.4603 - f1: 0.4544 - val_loss: 3.2902 - val_accuracy: 0.4318 - val_f1: 0.4216\n",
      "\n",
      "Epoch 00004: f1 improved from 0.38411 to 0.45441, saving model to models/doc_classifier.ckpt\n",
      "Epoch 5/30\n",
      "1184/1184 [==============================] - 44s 37ms/step - loss: 3.3818 - accuracy: 0.5287 - f1: 0.5199 - val_loss: 2.9169 - val_accuracy: 0.5379 - val_f1: 0.5143\n",
      "\n",
      "Epoch 00005: f1 improved from 0.45441 to 0.51989, saving model to models/doc_classifier.ckpt\n",
      "Epoch 6/30\n",
      "1184/1184 [==============================] - 43s 36ms/step - loss: 2.9308 - accuracy: 0.5760 - f1: 0.5831 - val_loss: 2.7237 - val_accuracy: 0.5227 - val_f1: 0.4933\n",
      "\n",
      "Epoch 00006: f1 improved from 0.51989 to 0.58311, saving model to models/doc_classifier.ckpt\n",
      "Epoch 7/30\n",
      "1184/1184 [==============================] - 44s 37ms/step - loss: 2.4553 - accuracy: 0.6427 - f1: 0.6521 - val_loss: 2.4463 - val_accuracy: 0.5758 - val_f1: 0.5370\n",
      "\n",
      "Epoch 00007: f1 improved from 0.58311 to 0.65214, saving model to models/doc_classifier.ckpt\n",
      "Epoch 8/30\n",
      "1184/1184 [==============================] - 44s 37ms/step - loss: 2.1217 - accuracy: 0.6926 - f1: 0.7020 - val_loss: 2.3095 - val_accuracy: 0.5682 - val_f1: 0.5413\n",
      "\n",
      "Epoch 00008: f1 improved from 0.65214 to 0.70201, saving model to models/doc_classifier.ckpt\n",
      "Epoch 9/30\n",
      "1184/1184 [==============================] - 42s 36ms/step - loss: 1.7744 - accuracy: 0.7323 - f1: 0.7511 - val_loss: 2.2428 - val_accuracy: 0.5152 - val_f1: 0.5310\n",
      "\n",
      "Epoch 00009: f1 improved from 0.70201 to 0.75113, saving model to models/doc_classifier.ckpt\n",
      "Epoch 10/30\n",
      "1184/1184 [==============================] - 44s 37ms/step - loss: 1.5104 - accuracy: 0.7618 - f1: 0.7822 - val_loss: 1.9837 - val_accuracy: 0.6439 - val_f1: 0.5991\n",
      "\n",
      "Epoch 00010: f1 improved from 0.75113 to 0.78216, saving model to models/doc_classifier.ckpt\n",
      "Epoch 11/30\n",
      "1184/1184 [==============================] - 45s 38ms/step - loss: 1.2243 - accuracy: 0.8117 - f1: 0.8208 - val_loss: 1.8931 - val_accuracy: 0.5909 - val_f1: 0.5965\n",
      "\n",
      "Epoch 00011: f1 improved from 0.78216 to 0.82084, saving model to models/doc_classifier.ckpt\n",
      "Epoch 12/30\n",
      "1184/1184 [==============================] - 43s 36ms/step - loss: 1.0397 - accuracy: 0.8361 - f1: 0.8518 - val_loss: 1.7505 - val_accuracy: 0.6439 - val_f1: 0.6216\n",
      "\n",
      "Epoch 00012: f1 improved from 0.82084 to 0.85179, saving model to models/doc_classifier.ckpt\n",
      "Epoch 13/30\n",
      "1184/1184 [==============================] - 44s 37ms/step - loss: 0.9322 - accuracy: 0.8429 - f1: 0.8686 - val_loss: 1.6515 - val_accuracy: 0.6667 - val_f1: 0.6466\n",
      "\n",
      "Epoch 00013: f1 improved from 0.85179 to 0.86861, saving model to models/doc_classifier.ckpt\n",
      "Epoch 14/30\n",
      "1184/1184 [==============================] - 45s 38ms/step - loss: 0.7824 - accuracy: 0.8742 - f1: 0.8829 - val_loss: 1.5873 - val_accuracy: 0.6364 - val_f1: 0.6494\n",
      "\n",
      "Epoch 00014: f1 improved from 0.86861 to 0.88288, saving model to models/doc_classifier.ckpt\n",
      "Epoch 15/30\n",
      "1184/1184 [==============================] - 42s 36ms/step - loss: 0.6802 - accuracy: 0.8818 - f1: 0.8976 - val_loss: 1.4953 - val_accuracy: 0.6591 - val_f1: 0.6667\n",
      "\n",
      "Epoch 00015: f1 improved from 0.88288 to 0.89763, saving model to models/doc_classifier.ckpt\n",
      "Epoch 16/30\n",
      "1184/1184 [==============================] - 41s 35ms/step - loss: 0.5895 - accuracy: 0.8860 - f1: 0.9037 - val_loss: 1.4208 - val_accuracy: 0.6667 - val_f1: 0.6667\n",
      "\n",
      "Epoch 00016: f1 improved from 0.89763 to 0.90367, saving model to models/doc_classifier.ckpt\n",
      "Epoch 17/30\n",
      "1184/1184 [==============================] - 41s 35ms/step - loss: 0.5050 - accuracy: 0.8860 - f1: 0.9046 - val_loss: 1.3649 - val_accuracy: 0.6818 - val_f1: 0.6553\n",
      "\n",
      "Epoch 00017: f1 improved from 0.90367 to 0.90461, saving model to models/doc_classifier.ckpt\n",
      "Epoch 18/30\n",
      "1184/1184 [==============================] - 41s 35ms/step - loss: 0.4231 - accuracy: 0.9003 - f1: 0.9214 - val_loss: 1.2988 - val_accuracy: 0.6667 - val_f1: 0.6610\n",
      "\n",
      "Epoch 00018: f1 improved from 0.90461 to 0.92140, saving model to models/doc_classifier.ckpt\n",
      "Epoch 19/30\n",
      "1184/1184 [==============================] - 43s 36ms/step - loss: 0.3593 - accuracy: 0.9029 - f1: 0.9192 - val_loss: 1.2626 - val_accuracy: 0.6667 - val_f1: 0.6803\n",
      "\n",
      "Epoch 00019: f1 did not improve from 0.92140\n",
      "Epoch 20/30\n",
      "1184/1184 [==============================] - 43s 36ms/step - loss: 0.2837 - accuracy: 0.9096 - f1: 0.9288 - val_loss: 1.2681 - val_accuracy: 0.6515 - val_f1: 0.6417\n",
      "\n",
      "Epoch 00020: f1 improved from 0.92140 to 0.92880, saving model to models/doc_classifier.ckpt\n",
      "Epoch 21/30\n",
      "1184/1184 [==============================] - 44s 37ms/step - loss: 0.2351 - accuracy: 0.9215 - f1: 0.9333 - val_loss: 1.1786 - val_accuracy: 0.6742 - val_f1: 0.6667\n",
      "\n",
      "Epoch 00021: f1 improved from 0.92880 to 0.93326, saving model to models/doc_classifier.ckpt\n",
      "Epoch 22/30\n",
      "1184/1184 [==============================] - 43s 36ms/step - loss: 0.1762 - accuracy: 0.9443 - f1: 0.9532 - val_loss: 1.1903 - val_accuracy: 0.6591 - val_f1: 0.6749\n",
      "\n",
      "Epoch 00022: f1 improved from 0.93326 to 0.95323, saving model to models/doc_classifier.ckpt\n",
      "Epoch 23/30\n",
      "1184/1184 [==============================] - 43s 36ms/step - loss: 0.1571 - accuracy: 0.9578 - f1: 0.9534 - val_loss: 1.1439 - val_accuracy: 0.6818 - val_f1: 0.6833\n",
      "\n",
      "Epoch 00023: f1 improved from 0.95323 to 0.95342, saving model to models/doc_classifier.ckpt\n",
      "Epoch 24/30\n",
      "1184/1184 [==============================] - 44s 37ms/step - loss: 0.1240 - accuracy: 0.9637 - f1: 0.9625 - val_loss: 1.1249 - val_accuracy: 0.6818 - val_f1: 0.6860\n",
      "\n",
      "Epoch 00024: f1 improved from 0.95342 to 0.96245, saving model to models/doc_classifier.ckpt\n",
      "Epoch 25/30\n",
      "1184/1184 [==============================] - 42s 36ms/step - loss: 0.1073 - accuracy: 0.9797 - f1: 0.9722 - val_loss: 1.1215 - val_accuracy: 0.6667 - val_f1: 0.6888\n",
      "\n",
      "Epoch 00025: f1 improved from 0.96245 to 0.97220, saving model to models/doc_classifier.ckpt\n",
      "Epoch 26/30\n",
      "1184/1184 [==============================] - 45s 38ms/step - loss: 0.0874 - accuracy: 0.9873 - f1: 0.9793 - val_loss: 1.1013 - val_accuracy: 0.6818 - val_f1: 0.6805\n",
      "\n",
      "Epoch 00026: f1 improved from 0.97220 to 0.97927, saving model to models/doc_classifier.ckpt\n",
      "Epoch 27/30\n",
      "1184/1184 [==============================] - 42s 36ms/step - loss: 0.0757 - accuracy: 0.9873 - f1: 0.9866 - val_loss: 1.0885 - val_accuracy: 0.6742 - val_f1: 0.6805\n",
      "\n",
      "Epoch 00027: f1 improved from 0.97927 to 0.98657, saving model to models/doc_classifier.ckpt\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 44s 37ms/step - loss: 0.0764 - accuracy: 0.9856 - f1: 0.9830 - val_loss: 1.0813 - val_accuracy: 0.6742 - val_f1: 0.6888\n",
      "\n",
      "Epoch 00028: f1 did not improve from 0.98657\n",
      "Epoch 29/30\n",
      "1184/1184 [==============================] - 44s 38ms/step - loss: 0.0688 - accuracy: 0.9882 - f1: 0.9855 - val_loss: 1.0617 - val_accuracy: 0.6667 - val_f1: 0.6862\n",
      "\n",
      "Epoch 00029: f1 did not improve from 0.98657\n",
      "Epoch 30/30\n",
      "1184/1184 [==============================] - 45s 38ms/step - loss: 0.0632 - accuracy: 0.9907 - f1: 0.9905 - val_loss: 1.0701 - val_accuracy: 0.6818 - val_f1: 0.6582\n",
      "\n",
      "Epoch 00030: f1 improved from 0.98657 to 0.99050, saving model to models/doc_classifier.ckpt\n",
      "Sess saved in path: models/sess2.ckpt\n",
      "Training Accuracy:  92.17 %\n",
      "Training F1:  91.25 %\n",
      "Training Loss:  0.27510066869411065\n",
      "1316/1316 [==============================] - 8s 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96        85\n",
      "           1       1.00      0.92      0.96        77\n",
      "           2       0.95      0.93      0.94       191\n",
      "           3       0.95      0.97      0.96        78\n",
      "           4       0.92      0.99      0.96       199\n",
      "           5       0.97      0.94      0.95        33\n",
      "           6       0.99      0.94      0.96       213\n",
      "           7       1.00      0.53      0.70       107\n",
      "           8       0.76      0.98      0.86       205\n",
      "           9       0.96      0.96      0.96       128\n",
      "\n",
      "    accuracy                           0.92      1316\n",
      "   macro avg       0.95      0.91      0.92      1316\n",
      "weighted avg       0.93      0.92      0.92      1316\n",
      "\n",
      "-----------------------------------------------------------------------------------\n",
      "Test Accuracy:  74.34 %\n",
      "Test F1:  75.03 %\n",
      "Test Loss:  0.8133159950771163\n",
      "565/565 [==============================] - 3s 5ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.70      0.70        27\n",
      "           1       1.00      0.41      0.58        37\n",
      "           2       0.83      0.74      0.78        77\n",
      "           3       0.54      0.64      0.58        33\n",
      "           4       0.84      0.97      0.90        78\n",
      "           5       0.62      0.38      0.48        13\n",
      "           6       0.82      0.78      0.80        93\n",
      "           7       0.58      0.18      0.28        38\n",
      "           8       0.63      0.91      0.74       107\n",
      "           9       0.81      0.81      0.81        62\n",
      "\n",
      "    accuracy                           0.74       565\n",
      "   macro avg       0.74      0.65      0.67       565\n",
      "weighted avg       0.76      0.74      0.73       565\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add an op to initialize the variables.\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Later, launch the model, initialize the variables, do some work, and save the\n",
    "# variables to disk.\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    # Do some work with the model\n",
    "    # train LSTM\n",
    "    history = doc_classifier.fit([x_img_train, x_txt_train], y_train,\n",
    "                    batch_size=256, \n",
    "                    epochs=30, \n",
    "                    shuffle=False,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=cbks,\n",
    "                    verbose=1)\n",
    "    save_path = saver.save(sess, \"models/sess2.ckpt\")\n",
    "    print(\"Sess saved in path: %s\" % save_path)\n",
    "    \n",
    "    ##Save model weights\n",
    "    doc_classifier.save_weights('models/doc_classifier2.h5')\n",
    "    \n",
    "    model_json = doc_classifier.to_json()\n",
    "    with open('model2.json', 'w') as json_file:\n",
    "        json_file.write(model_json)\n",
    "    doc_classifier.save_weights('model2.h5')\n",
    "    \n",
    "    loss, accuracy, f1 = doc_classifier.evaluate([x_img_train, x_txt_train], y_train, verbose=2)\n",
    "    print(\"Training Accuracy: \", round(accuracy*100, 2),\"%\" )\n",
    "    print(\"Training F1: \", round(f1*100, 2),\"%\" )\n",
    "    print(\"Training Loss: \", loss )\n",
    "    print(mu.get_model_metrics(doc_classifier, [x_img_train, x_txt_train], y_train))\n",
    "    print('-----------------------------------------------------------------------------------')\n",
    "    loss, accuracy, f1 = doc_classifier.evaluate([x_img_test, x_txt_test], y_test, verbose=2)\n",
    "    print(\"Test Accuracy: \", round(accuracy*100, 2),\"%\" )\n",
    "    print(\"Test F1: \", round(f1*100, 2),\"%\" )\n",
    "    print(\"Test Loss: \", loss )\n",
    "    print(mu.get_model_metrics(doc_classifier, [x_img_test, x_txt_test], y_test))\n",
    "\n",
    "#mu.plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from models/sess.ckpt\n",
      "Session restored.\n",
      "Restored model, train accuracy: 88.83%\n",
      "Restored model, test accuracy: 37.52%\n"
     ]
    }
   ],
   "source": [
    "from keras_self_attention import SeqSelfAttention\n",
    "from keras.optimizers import Adagrad\n",
    "\n",
    "tf.reset_default_graph()\n",
    "# Add ops to save and restore all the variables.\n",
    "#saver = tf.train.Saver()\n",
    "\n",
    "# Later, launch the model, use the saver to restore variables from disk, and\n",
    "# do some work with the model.\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    json_file = open('model.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = keras.models.model_from_json(loaded_model_json, custom_objects={'SeqSelfAttention': SeqSelfAttention})\n",
    "    loaded_model.load_weights('model.h5')\n",
    "\n",
    "    opt = Adagrad(lr = 1e-3)\n",
    "        #sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    loaded_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "    graph = tf.get_default_graph()\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    # Restore variables from disk.\n",
    "    saver.restore(sess, \"models/sess.ckpt\")\n",
    "    print(\"Session restored.\")\n",
    "    \n",
    "    # Re-evaluate the model\n",
    "    with graph.as_default():\n",
    "        loss,acc = loaded_model.evaluate([x_img_train, x_txt_train], y_train, verbose=2)\n",
    "    print(\"Restored model, train accuracy: {:5.2f}%\".format(100*acc))\n",
    "    with graph.as_default():\n",
    "        loss,acc = loaded_model.evaluate([x_img_test, x_txt_test], y_test, verbose=2)\n",
    "    print(\"Restored model, test accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get model evaluation metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value bidirectional_1/forward_lstm_1/kernel\n\t [[node bidirectional_1/forward_lstm_1/kernel/read (defined at /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:376) ]]\n\nCaused by op 'bidirectional_1/forward_lstm_1/kernel/read', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-13-7256a0c6aafb>\", line 9, in <module>\n    doc_classifier = dcm.build_doc_classifier(max_len, x_img_train.shape[1], n_classes, vocab_size)\n  File \"/home/sureclaim/Documents/Claims/GPU_files/doc_classifier_model.py\", line 67, in build_doc_classifier\n    recurrent_dropout=0.2))(txt_attn)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\", line 576, in __call__\n    self.build(input_shapes[0])\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/wrappers.py\", line 320, in build\n    self.forward_layer.build(input_shape)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\", line 445, in build\n    self.cell.build(step_input_shape)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\", line 1707, in build\n    constraint=self.kernel_constraint)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\", line 87, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\", line 400, in add_weight\n    constraint=constraint)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 376, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 213, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 176, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 155, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2495, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 217, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 1395, in __init__\n    constraint=constraint)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 1557, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\", line 180, in wrapper\n    return target(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\", line 81, in identity\n    ret = gen_array_ops.identity(input, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 3890, in identity\n    \"Identity\", input=input, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value bidirectional_1/forward_lstm_1/kernel\n\t [[node bidirectional_1/forward_lstm_1/kernel/read (defined at /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:376) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value bidirectional_1/forward_lstm_1/kernel\n\t [[{{node bidirectional_1/forward_lstm_1/kernel/read}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f98a3dbf4f01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_img_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_txt_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Accuracy: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"%\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training F1: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"%\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Loss: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx_img_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_txt_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1690\u001b[0m                                \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m                                \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m                                steps=steps)\n\u001b[0m\u001b[1;32m   1693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m     def predict(self, x,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_test_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1368\u001b[0m                     \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2330\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2331\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2332\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2333\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value bidirectional_1/forward_lstm_1/kernel\n\t [[node bidirectional_1/forward_lstm_1/kernel/read (defined at /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:376) ]]\n\nCaused by op 'bidirectional_1/forward_lstm_1/kernel/read', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-13-7256a0c6aafb>\", line 9, in <module>\n    doc_classifier = dcm.build_doc_classifier(max_len, x_img_train.shape[1], n_classes, vocab_size)\n  File \"/home/sureclaim/Documents/Claims/GPU_files/doc_classifier_model.py\", line 67, in build_doc_classifier\n    recurrent_dropout=0.2))(txt_attn)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\", line 576, in __call__\n    self.build(input_shapes[0])\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/wrappers.py\", line 320, in build\n    self.forward_layer.build(input_shape)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\", line 445, in build\n    self.cell.build(step_input_shape)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\", line 1707, in build\n    constraint=self.kernel_constraint)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\", line 87, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\", line 400, in add_weight\n    constraint=constraint)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 376, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 213, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 176, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 155, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2495, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 217, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 1395, in __init__\n    constraint=constraint)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 1557, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\", line 180, in wrapper\n    return target(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\", line 81, in identity\n    ret = gen_array_ops.identity(input, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 3890, in identity\n    \"Identity\", input=input, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value bidirectional_1/forward_lstm_1/kernel\n\t [[node bidirectional_1/forward_lstm_1/kernel/read (defined at /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:376) ]]\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, f1 = doc_classifier.evaluate([x_img_train, x_txt_train], y_train, verbose=2)\n",
    "print(\"Training Accuracy: \", round(accuracy*100, 2),\"%\" )\n",
    "print(\"Training F1: \", round(f1*100, 2),\"%\" )\n",
    "print(\"Training Loss: \", loss )\n",
    "print(mu.get_model_metrics(doc_classifier, [x_img_train, x_txt_train], y_train))\n",
    "print('-----------------------------------------------------------------------------------')\n",
    "loss, accuracy, f1 = doc_classifier.evaluate([x_img_test, x_txt_test], y_test, verbose=2)\n",
    "print(\"Test Accuracy: \", round(accuracy*100, 2),\"%\" )\n",
    "print(\"Test F1: \", round(f1*100, 2),\"%\" )\n",
    "print(\"Test Loss: \", loss )\n",
    "print(mu.get_model_metrics(doc_classifier, [x_img_test, x_txt_test], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = doc_classifier.to_json()\n",
    "with open('model.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "doc_classifier.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored model, accuracy: 52.96%\n"
     ]
    }
   ],
   "source": [
    "from keras_self_attention import SeqSelfAttention\n",
    "\n",
    "#del loaded_model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = keras.models.model_from_json(loaded_model_json, custom_objects={'SeqSelfAttention': SeqSelfAttention})\n",
    "loaded_model.load_weights('model.h5')\n",
    "\n",
    "opt = Adam(lr = 1e-3)\n",
    "#sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "loaded_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "graph = tf.get_default_graph()\n",
    "# Re-evaluate the model\n",
    "loss,acc = loaded_model.evaluate([x_img_train, x_txt_train], y_train, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained model, accuracy: 10.03%\n",
      "Restored model, accuracy: 81.84%\n"
     ]
    }
   ],
   "source": [
    "# Create a basic model instance\n",
    "with open('model_config', 'r') as configfile:\n",
    "    config = json.load(configfile)\n",
    "    \n",
    "model = dcm.build_doc_classifier(config['input_text_shape'], config['input_img_shape'], config['n_classes'], config['vocab_size'])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, acc, f1 = model.evaluate([x_img_train, x_txt_train], y_train, verbose=2)\n",
    "print(\"Untrained model, accuracy: {:5.2f}%\".format(100*acc))\n",
    "\n",
    "\n",
    "# Loads the weights\n",
    "\n",
    "model.load_weights(\"models/doc_classifier.ckpt\")\n",
    "\n",
    "# Re-evaluate the model\n",
    "loss,acc, f1 = model.evaluate([x_img_train, x_txt_train], y_train, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Train_Doc_Classifier",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
